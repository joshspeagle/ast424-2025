{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Getting Started with the Multimodal Universe\n",
    "\n",
    "Welcome to your first tutorial! This notebook will help you:\n",
    "- Check your Python environment\n",
    "- Load your first dataset from the Multimodal Universe\n",
    "- Understand the data structure\n",
    "- Make your first visualization\n",
    "- Save data for offline work\n",
    "\n",
    "**Expected runtime: 5 minutes**\n",
    "\n",
    "**Note**: All datasets are at https://huggingface.co/MultimodalUniverse/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Check\n",
    "\n",
    "Let's first make sure you have all the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Import required packages\n",
    "import numpy as np\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "\n",
    "import pandas as pd\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import astropy\n",
    "print(f\"Astropy version: {astropy.__version__}\")\n",
    "\n",
    "# Most importantly, the datasets library\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "print(f\"Datasets version: {datasets.__version__}\")\n",
    "\n",
    "import pickle  # For saving data\n",
    "\n",
    "print(\"\\n✅ All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Your First Dataset Load\n",
    "\n",
    "Let's start with the PLAsTiCC dataset - it's relatively small and loads quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PLAsTiCC dataset in streaming mode\n",
    "# Streaming mode means we don't download the whole dataset at once\n",
    "print(\"Loading PLAsTiCC dataset in streaming mode...\")\n",
    "dataset = load_dataset(\n",
    "    \"MultimodalUniverse/plasticc\",\n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "print(\"✅ Dataset loaded successfully!\")\n",
    "print(f\"Dataset type: {type(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring Data Structure\n",
    "\n",
    "PLAsTiCC contains simulated light curves for the LSST survey. Let's explore the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first example\n",
    "example = next(iter(dataset))\n",
    "\n",
    "# See what fields are available\n",
    "print(\"Available fields in the dataset:\")\n",
    "print(\"-\" * 40)\n",
    "for key in example.keys():\n",
    "    value = example[key]\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"{key:20s} : dict with keys {list(value.keys())}\")\n",
    "    elif isinstance(value, np.ndarray):\n",
    "        print(f\"{key:20s} : array with shape {value.shape}\")\n",
    "    elif isinstance(value, (int, float)):\n",
    "        print(f\"{key:20s} : {type(value).__name__} = {value}\")\n",
    "    else:\n",
    "        print(f\"{key:20s} : {type(value).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the lightcurve structure\n",
    "print(\"Lightcurve structure:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Object ID: {example['object_id']}\")\n",
    "print(f\"Object Type: {example['obj_type']}\")\n",
    "print(f\"Redshift: {example['redshift']:.4f}\")\n",
    "\n",
    "# The lightcurve is stored as a dictionary\n",
    "lightcurve = example['lightcurve']\n",
    "print(f\"Lightcurve keys: {list(lightcurve.keys())}\")\n",
    "\n",
    "# Extract the components\n",
    "times = np.array(lightcurve['time'])\n",
    "bands = np.array(lightcurve['band'])\n",
    "flux = np.array(lightcurve['flux'])\n",
    "flux_err = np.array(lightcurve['flux_err'])\n",
    "\n",
    "print(f\"\\nNumber of observations: {len(times)}\")\n",
    "print(f\"Unique bands: {np.unique(bands)}\")\n",
    "print(f\"Time range: {times.min():.1f} to {times.max():.1f} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Your First Visualization\n",
    "\n",
    "Let's plot the light curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Define colors for each band\n",
    "band_colors = {'u': 'purple', 'g': 'blue', 'r': 'green',\n",
    "               'i': 'orange', 'z': 'red', 'Y': 'darkred'}\n",
    "\n",
    "# Plot each band separately\n",
    "for band_name in np.unique(bands):\n",
    "    # Get data for this band\n",
    "    mask = bands == band_name\n",
    "    \n",
    "    if band_name in band_colors:\n",
    "        color = band_colors[band_name]\n",
    "    else:\n",
    "        color = 'gray'\n",
    "    \n",
    "    # Plot with error bars\n",
    "    plt.errorbar(times[mask], flux[mask], yerr=flux_err[mask],\n",
    "                fmt='o', label=f'Band {band_name}',\n",
    "                color=color, alpha=0.7, markersize=4)\n",
    "\n",
    "plt.xlabel('Time (days)', fontsize=12)\n",
    "plt.ylabel('Flux', fontsize=12)\n",
    "plt.title(f'PLAsTiCC Light Curve - {example[\"obj_type\"]} (z={example[\"redshift\"]:.3f})',\n",
    "         fontsize=14)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loading Multiple Examples\n",
    "\n",
    "Let's load several examples and see the variety in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 10 examples\n",
    "examples = []\n",
    "dataset_iter = iter(dataset)\n",
    "\n",
    "print(\"Loading 10 examples...\")\n",
    "for i in range(10):\n",
    "    example = next(dataset_iter)\n",
    "    examples.append({\n",
    "        'object_id': example['object_id'],\n",
    "        'obj_type': example['obj_type'],\n",
    "        'redshift': example['redshift'],\n",
    "        'num_observations': len(example['lightcurve']['time'])\n",
    "    })\n",
    "    print(f\"  Loaded object {i+1}/10: ID={example['object_id']}\")\n",
    "\n",
    "# Convert to DataFrame for easy viewing\n",
    "df = pd.DataFrame(examples)\n",
    "print(\"\\nSummary of loaded objects:\")\n",
    "print(df)\n",
    "\n",
    "# Show statistics\n",
    "print(\"\\nObject type distribution:\")\n",
    "print(df['obj_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loading Without Streaming\n",
    "\n",
    "For development, you might want to download a subset for faster access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first 100 examples (downloads to cache)\n",
    "print(\"Downloading first 100 examples (this may take a moment)...\")\n",
    "dataset_subset = load_dataset(\n",
    "    \"MultimodalUniverse/plasticc\",\n",
    "    split=\"train[:100]\"\n",
    ")\n",
    "\n",
    "print(f\"✅ Downloaded {len(dataset_subset)} examples\")\n",
    "print(\"These are now cached locally for fast access\")\n",
    "\n",
    "# You can now access by index\n",
    "first_example = dataset_subset[0]\n",
    "print(f\"\\nFirst object ID: {first_example['object_id']}\")\n",
    "print(f\"Object type: {first_example['obj_type']}\")\n",
    "\n",
    "# Show some statistics\n",
    "obj_types = [dataset_subset[i]['obj_type'] for i in range(len(dataset_subset))]\n",
    "unique_types = pd.Series(obj_types).value_counts()\n",
    "print(\"\\nObject types in subset:\")\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving Data for Offline Work\n",
    "\n",
    "You can save subsets for working without internet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert subset to pandas DataFrame\n",
    "print(\"Creating summary DataFrame...\")\n",
    "data_list = []\n",
    "for i in range(min(20, len(dataset_subset))):  # Save first 20\n",
    "    obj = dataset_subset[i]\n",
    "    data_list.append({\n",
    "        'object_id': obj['object_id'],\n",
    "        'obj_type': obj['obj_type'],\n",
    "        'redshift': obj['redshift'],\n",
    "        'hostgal_photoz': obj['hostgal_photoz'],\n",
    "        'num_observations': len(obj['lightcurve']['time'])\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'plasticc_sample.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"✅ Saved {len(df)} objects to {output_file}\")\n",
    "\n",
    "# Save first 5 light curves as pickle (preserves structure)\n",
    "light_curves = []\n",
    "for i in range(min(5, len(dataset_subset))):\n",
    "    lc = dataset_subset[i]['lightcurve']\n",
    "    light_curves.append({\n",
    "        'object_id': dataset_subset[i]['object_id'],\n",
    "        'lightcurve': lc\n",
    "    })\n",
    "\n",
    "with open('plasticc_lightcurves.pkl', 'wb') as f:\n",
    "    pickle.dump(light_curves, f)\n",
    "print(f\"✅ Saved {len(light_curves)} light curves to plasticc_lightcurves.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "Congratulations! You've successfully:\n",
    "✅ Loaded data from the Multimodal Universe\n",
    "✅ Explored the PLAsTiCC data structure\n",
    "✅ Created your first visualization\n",
    "✅ Learned how to save data locally\n",
    "\n",
    "### Key Takeaways:\n",
    "1. Use `streaming=True` for exploration without downloading everything\n",
    "2. Use `split=\"train[:N]\"` to download specific number of examples\n",
    "3. PLAsTiCC uses dictionary structure for light curves\n",
    "4. Data can be saved as CSV (metadata) and pickle (full structure)\n",
    "\n",
    "### Available Datasets to Explore:\n",
    "- `MultimodalUniverse/plasticc` - Time series\n",
    "- `MultimodalUniverse/gaia` - Catalog (ra, dec lowercase)\n",
    "- `MultimodalUniverse/tess` - Time series (RA, DEC uppercase)\n",
    "- `MultimodalUniverse/gz10` - Galaxies (rgb_image, gz10_label)\n",
    "- `MultimodalUniverse/sdss` - Spectra\n",
    "- `MultimodalUniverse/chandra` - X-ray\n",
    "\n",
    "All datasets: https://huggingface.co/MultimodalUniverse/datasets\n",
    "\n",
    "### Next Tutorial:\n",
    "Continue to `02_data_types.ipynb` to explore images, spectra, and catalogs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}